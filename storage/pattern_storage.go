// storage/pattern_storage.go - Persists discovered code patterns
package storage

import (
	"context"
	"database/sql"
	"encoding/json"
	"fmt"
	"strings"
	"sync"
	"time"

	"github.com/yourusername/ai-code-assistant/internal/learning"
)

// StoredPattern represents a persisted code pattern
type StoredPattern struct {
	ID              string                 `json:"id" db:"id"`
	Name            string                 `json:"name" db:"name"`
	Description     string                 `json:"description" db:"description"`
	Category        string                 `json:"category" db:"category"` // design, architectural, anti-pattern, etc.
	Language        string                 `json:"language" db:"language"`
	Pattern         string                 `json:"pattern" db:"pattern"`                 // The actual code pattern
	Examples        []string               `json:"examples" db:"examples"`               // JSON array of example usages
	Occurrences     int                    `json:"occurrences" db:"occurrences"`         // How often this pattern appears
	Confidence      float64                `json:"confidence" db:"confidence"`           // Pattern detection confidence (0-1)
	Complexity      int                    `json:"complexity" db:"complexity"`           // Pattern complexity rating
	Impact          string                 `json:"impact" db:"impact"`                   // positive, negative, neutral
	Recommendations []string               `json:"recommendations" db:"recommendations"` // JSON array of suggestions
	Tags            []string               `json:"tags" db:"tags"`                       // JSON array of tags
	Metadata        map[string]interface{} `json:"metadata" db:"metadata"`               // Additional pattern metadata
	FirstSeen       time.Time              `json:"first_seen" db:"first_seen"`
	LastSeen        time.Time              `json:"last_seen" db:"last_seen"`
	CreatedAt       time.Time              `json:"created_at" db:"created_at"`
	UpdatedAt       time.Time              `json:"updated_at" db:"updated_at"`
	ProjectPaths    []string               `json:"project_paths" db:"project_paths"`   // Projects where pattern was found
	FilePatterns    []string               `json:"file_patterns" db:"file_patterns"`   // File path patterns
	UserRating      float64                `json:"user_rating" db:"user_rating"`       // User feedback rating
	AutoGenerated   bool                   `json:"auto_generated" db:"auto_generated"` // Whether pattern was auto-discovered
}

// PatternOccurrence represents a specific occurrence of a pattern
type PatternOccurrence struct {
	ID          string                 `json:"id" db:"id"`
	PatternID   string                 `json:"pattern_id" db:"pattern_id"`
	FilePath    string                 `json:"file_path" db:"file_path"`
	LineStart   int                    `json:"line_start" db:"line_start"`
	LineEnd     int                    `json:"line_end" db:"line_end"`
	Code        string                 `json:"code" db:"code"`
	Context     string                 `json:"context" db:"context"`       // Surrounding code context
	Confidence  float64                `json:"confidence" db:"confidence"` // Confidence of this specific match
	Properties  map[string]interface{} `json:"properties" db:"properties"`
	DetectedAt  time.Time              `json:"detected_at" db:"detected_at"`
	ProjectPath string                 `json:"project_path" db:"project_path"`
	SessionID   string                 `json:"session_id" db:"session_id,omitempty"`
}

// PatternStats represents aggregated pattern statistics
type PatternStats struct {
	TotalPatterns      int              `json:"total_patterns"`
	PatternsByCategory map[string]int   `json:"patterns_by_category"`
	PatternsByLanguage map[string]int   `json:"patterns_by_language"`
	PatternsByImpact   map[string]int   `json:"patterns_by_impact"`
	MostFrequent       []*StoredPattern `json:"most_frequent"`
	RecentlyDiscovered []*StoredPattern `json:"recently_discovered"`
	TopRated           []*StoredPattern `json:"top_rated"`
	TrendingPatterns   []*PatternTrend  `json:"trending_patterns"`
	TotalOccurrences   int              `json:"total_occurrences"`
	AverageConfidence  float64          `json:"average_confidence"`
}

// PatternTrend represents trending pattern data
type PatternTrend struct {
	PatternID        string           `json:"pattern_id"`
	PatternName      string           `json:"pattern_name"`
	OccurrenceGrowth float64          `json:"occurrence_growth"` // Growth rate over time period
	TimeFrame        string           `json:"time_frame"`        // week, month, quarter
	DataPoints       []TrendDataPoint `json:"data_points"`
}

// TrendDataPoint represents a single data point in a trend
type TrendDataPoint struct {
	Timestamp  time.Time `json:"timestamp"`
	Count      int       `json:"count"`
	Confidence float64   `json:"confidence"`
}

// PatternQuery represents search criteria for patterns
type PatternQuery struct {
	Categories     []string   `json:"categories,omitempty"`
	Languages      []string   `json:"languages,omitempty"`
	Tags           []string   `json:"tags,omitempty"`
	ProjectPaths   []string   `json:"project_paths,omitempty"`
	MinConfidence  float64    `json:"min_confidence,omitempty"`
	MinOccurrences int        `json:"min_occurrences,omitempty"`
	Impact         string     `json:"impact,omitempty"`
	SearchText     string     `json:"search_text,omitempty"`
	TimeRange      *TimeRange `json:"time_range,omitempty"`
	SortBy         string     `json:"sort_by,omitempty"`    // confidence, occurrences, created_at, rating
	SortOrder      string     `json:"sort_order,omitempty"` // asc, desc
	Limit          int        `json:"limit,omitempty"`
	Offset         int        `json:"offset,omitempty"`
}

// PatternStorage provides storage operations for code patterns
type PatternStorage struct {
	db      *sql.DB
	cache   *PatternCache
	mutex   sync.RWMutex
	indexer *PatternIndexer // For full-text search capabilities
}

// PatternIndexer provides search indexing for patterns
type PatternIndexer struct {
	patterns map[string]*StoredPattern // In-memory index for quick searches
	mutex    sync.RWMutex
}

// NewPatternStorage creates a new pattern storage instance
func NewPatternStorage(db *sql.DB) (*PatternStorage, error) {
	ps := &PatternStorage{
		db:    db,
		cache: NewPatternCache(),
		indexer: &PatternIndexer{
			patterns: make(map[string]*StoredPattern),
		},
	}

	// Initialize database schema
	if err := ps.initializeSchema(); err != nil {
		return nil, fmt.Errorf("failed to initialize pattern storage schema: %w", err)
	}

	// Load patterns into indexer
	go ps.loadIndex()

	return ps, nil
}

// initializeSchema creates the necessary database tables
func (ps *PatternStorage) initializeSchema() error {
	queries := []string{
		`CREATE TABLE IF NOT EXISTS patterns (
			id TEXT PRIMARY KEY,
			name TEXT NOT NULL,
			description TEXT,
			category TEXT,
			language TEXT,
			pattern TEXT NOT NULL,
			examples TEXT, -- JSON array
			occurrences INTEGER DEFAULT 0,
			confidence REAL DEFAULT 0.0,
			complexity INTEGER DEFAULT 0,
			impact TEXT DEFAULT 'neutral',
			recommendations TEXT, -- JSON array
			tags TEXT, -- JSON array
			metadata TEXT, -- JSON object
			first_seen DATETIME,
			last_seen DATETIME,
			created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
			updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
			project_paths TEXT, -- JSON array
			file_patterns TEXT, -- JSON array
			user_rating REAL DEFAULT 0.0,
			auto_generated BOOLEAN DEFAULT 1
		)`,

		`CREATE TABLE IF NOT EXISTS pattern_occurrences (
			id TEXT PRIMARY KEY,
			pattern_id TEXT NOT NULL,
			file_path TEXT NOT NULL,
			line_start INTEGER,
			line_end INTEGER,
			code TEXT,
			context TEXT,
			confidence REAL DEFAULT 0.0,
			properties TEXT, -- JSON object
			detected_at DATETIME DEFAULT CURRENT_TIMESTAMP,
			project_path TEXT,
			session_id TEXT,
			FOREIGN KEY (pattern_id) REFERENCES patterns(id) ON DELETE CASCADE
		)`,

		// Indexes for performance
		`CREATE INDEX IF NOT EXISTS idx_patterns_category ON patterns(category)`,
		`CREATE INDEX IF NOT EXISTS idx_patterns_language ON patterns(language)`,
		`CREATE INDEX IF NOT EXISTS idx_patterns_impact ON patterns(impact)`,
		`CREATE INDEX IF NOT EXISTS idx_patterns_confidence ON patterns(confidence)`,
		`CREATE INDEX IF NOT EXISTS idx_patterns_occurrences ON patterns(occurrences)`,
		`CREATE INDEX IF NOT EXISTS idx_patterns_created_at ON patterns(created_at)`,
		`CREATE INDEX IF NOT EXISTS idx_patterns_rating ON patterns(user_rating)`,

		`CREATE INDEX IF NOT EXISTS idx_occurrences_pattern ON pattern_occurrences(pattern_id)`,
		`CREATE INDEX IF NOT EXISTS idx_occurrences_file ON pattern_occurrences(file_path)`,
		`CREATE INDEX IF NOT EXISTS idx_occurrences_project ON pattern_occurrences(project_path)`,
		`CREATE INDEX IF NOT EXISTS idx_occurrences_detected ON pattern_occurrences(detected_at)`,

		// Full-text search indexes (SQLite FTS)
		`CREATE VIRTUAL TABLE IF NOT EXISTS patterns_fts USING fts5(
			id UNINDEXED,
			name,
			description,
			pattern,
			tags,
			content='patterns',
			content_rowid='rowid'
		)`,

		// FTS triggers to keep search index in sync
		`CREATE TRIGGER IF NOT EXISTS patterns_fts_insert AFTER INSERT ON patterns BEGIN
			INSERT INTO patterns_fts(id, name, description, pattern, tags) 
			VALUES (NEW.id, NEW.name, NEW.description, NEW.pattern, NEW.tags);
		END`,

		`CREATE TRIGGER IF NOT EXISTS patterns_fts_update AFTER UPDATE ON patterns BEGIN
			UPDATE patterns_fts SET name=NEW.name, description=NEW.description, pattern=NEW.pattern, tags=NEW.tags 
			WHERE id=NEW.id;
		END`,

		`CREATE TRIGGER IF NOT EXISTS patterns_fts_delete AFTER DELETE ON patterns BEGIN
			DELETE FROM patterns_fts WHERE id=OLD.id;
		END`,
	}

	for _, query := range queries {
		if _, err := ps.db.Exec(query); err != nil {
			return fmt.Errorf("failed to execute query: %s, error: %w", query, err)
		}
	}

	return nil
}

// StorePattern saves a code pattern to storage
func (ps *PatternStorage) StorePattern(ctx context.Context, pattern *learning.CodePattern) (*StoredPattern, error) {
	ps.mutex.Lock()
	defer ps.mutex.Unlock()

	// Convert learning.CodePattern to StoredPattern
	stored := &StoredPattern{
		ID:              pattern.ID,
		Name:            pattern.Name,
		Description:     pattern.Description,
		Category:        string(pattern.Type),
		Language:        pattern.Language,
		Pattern:         pattern.Code,
		Examples:        pattern.Examples,
		Occurrences:     1,
		Confidence:      pattern.Confidence,
		Complexity:      pattern.Complexity,
		Impact:          string(pattern.Impact),
		Recommendations: pattern.Improvements,
		Tags:            pattern.Tags,
		Metadata:        pattern.Metadata,
		FirstSeen:       time.Now(),
		LastSeen:        time.Now(),
		CreatedAt:       time.Now(),
		UpdatedAt:       time.Now(),
		ProjectPaths:    []string{pattern.ProjectPath},
		FilePatterns:    pattern.FilePatterns,
		AutoGenerated:   true,
	}

	// Check if pattern already exists
	existing, err := ps.getPatternByID(ctx, pattern.ID)
	if err == nil && existing != nil {
		// Update existing pattern
		stored = ps.mergePatterns(existing, stored)
		stored.Occurrences++
		stored.LastSeen = time.Now()
		stored.UpdatedAt = time.Now()

		// Add project path if not already present
		if !ps.containsString(stored.ProjectPaths, pattern.ProjectPath) {
			stored.ProjectPaths = append(stored.ProjectPaths, pattern.ProjectPath)
		}
	}

	// Serialize JSON fields
	examplesJSON, _ := json.Marshal(stored.Examples)
	recommendationsJSON, _ := json.Marshal(stored.Recommendations)
	tagsJSON, _ := json.Marshal(stored.Tags)
	metadataJSON, _ := json.Marshal(stored.Metadata)
	projectPathsJSON, _ := json.Marshal(stored.ProjectPaths)
	filePatternsJSON, _ := json.Marshal(stored.FilePatterns)

	// Insert or update pattern
	query := `INSERT OR REPLACE INTO patterns 
			(id, name, description, category, language, pattern, examples, occurrences, confidence, 
			 complexity, impact, recommendations, tags, metadata, first_seen, last_seen, created_at, 
			 updated_at, project_paths, file_patterns, user_rating, auto_generated)
			VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)`

	_, err = ps.db.ExecContext(ctx, query,
		stored.ID,
		stored.Name,
		stored.Description,
		stored.Category,
		stored.Language,
		stored.Pattern,
		string(examplesJSON),
		stored.Occurrences,
		stored.Confidence,
		stored.Complexity,
		stored.Impact,
		string(recommendationsJSON),
		string(tagsJSON),
		string(metadataJSON),
		stored.FirstSeen,
		stored.LastSeen,
		stored.CreatedAt,
		stored.UpdatedAt,
		string(projectPathsJSON),
		string(filePatternsJSON),
		stored.UserRating,
		stored.AutoGenerated,
	)

	if err != nil {
		return nil, fmt.Errorf("failed to store pattern: %w", err)
	}

	// Update cache and index
	ps.cache.SetPattern(stored.ID, &learning.CodePattern{
		ID:          stored.ID,
		Name:        stored.Name,
		Description: stored.Description,
		Code:        stored.Pattern,
		Language:    stored.Language,
		Confidence:  stored.Confidence,
	})

	ps.indexer.mutex.Lock()
	ps.indexer.patterns[stored.ID] = stored
	ps.indexer.mutex.Unlock()

	return stored, nil
}

// StoreOccurrence saves a specific pattern occurrence
func (ps *PatternStorage) StoreOccurrence(ctx context.Context, occurrence *PatternOccurrence) error {
	ps.mutex.Lock()
	defer ps.mutex.Unlock()

	propertiesJSON, _ := json.Marshal(occurrence.Properties)

	query := `INSERT INTO pattern_occurrences 
			(id, pattern_id, file_path, line_start, line_end, code, context, confidence, 
			 properties, detected_at, project_path, session_id)
			VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)`

	_, err := ps.db.ExecContext(ctx, query,
		occurrence.ID,
		occurrence.PatternID,
		occurrence.FilePath,
		occurrence.LineStart,
		occurrence.LineEnd,
		occurrence.Code,
		occurrence.Context,
		occurrence.Confidence,
		string(propertiesJSON),
		occurrence.DetectedAt,
		occurrence.ProjectPath,
		occurrence.SessionID,
	)

	return err
}

// GetPattern retrieves a pattern by ID
func (ps *PatternStorage) GetPattern(ctx context.Context, patternID string) (*StoredPattern, error) {
	// Check cache first
	if cached, found := ps.cache.GetPattern(patternID); found {
		// Convert back to StoredPattern (this is a simplified conversion)
		return ps.getPatternByID(ctx, patternID)
	}

	return ps.getPatternByID(ctx, patternID)
}

// QueryPatterns searches for patterns based on criteria
func (ps *PatternStorage) QueryPatterns(ctx context.Context, query *PatternQuery) ([]*StoredPattern, error) {
	ps.mutex.RLock()
	defer ps.mutex.RUnlock()

	sqlQuery := `SELECT id, name, description, category, language, pattern, examples, occurrences, 
				confidence, complexity, impact, recommendations, tags, metadata, first_seen, last_seen, 
				created_at, updated_at, project_paths, file_patterns, user_rating, auto_generated
				FROM patterns`

	args := make([]interface{}, 0)
	conditions := make([]string, 0)

	// Build WHERE conditions
	if len(query.Categories) > 0 {
		placeholders := make([]string, len(query.Categories))
		for i, category := range query.Categories {
			placeholders[i] = "?"
			args = append(args, category)
		}
		conditions = append(conditions, fmt.Sprintf("category IN (%s)", strings.Join(placeholders, ",")))
	}

	if len(query.Languages) > 0 {
		placeholders := make([]string, len(query.Languages))
		for i, lang := range query.Languages {
			placeholders[i] = "?"
			args = append(args, lang)
		}
		conditions = append(conditions, fmt.Sprintf("language IN (%s)", strings.Join(placeholders, ",")))
	}

	if query.MinConfidence > 0 {
		conditions = append(conditions, "confidence >= ?")
		args = append(args, query.MinConfidence)
	}

	if query.MinOccurrences > 0 {
		conditions = append(conditions, "occurrences >= ?")
		args = append(args, query.MinOccurrences)
	}

	if query.Impact != "" {
		conditions = append(conditions, "impact = ?")
		args = append(args, query.Impact)
	}

	// Add time range filter
	if query.TimeRange != nil {
		conditions = append(conditions, "created_at BETWEEN ? AND ?")
		args = append(args, query.TimeRange.Start, query.TimeRange.End)
	}

	// Full-text search
	if query.SearchText != "" {
		// Use FTS table for text search
		sqlQuery = `SELECT p.id, p.name, p.description, p.category, p.language, p.pattern, p.examples, 
					p.occurrences, p.confidence, p.complexity, p.impact, p.recommendations, p.tags, 
					p.metadata, p.first_seen, p.last_seen, p.created_at, p.updated_at, p.project_paths, 
					p.file_patterns, p.user_rating, p.auto_generated
					FROM patterns p
					JOIN patterns_fts fts ON p.id = fts.id
					WHERE patterns_fts MATCH ?`
		args = append([]interface{}{query.SearchText}, args...)
	}

	if len(conditions) > 0 {
		if query.SearchText != "" {
			sqlQuery += " AND " + strings.Join(conditions, " AND ")
		} else {
			sqlQuery += " WHERE " + strings.Join(conditions, " AND ")
		}
	}

	// Add sorting
	sortBy := "created_at"
	if query.SortBy != "" {
		sortBy = query.SortBy
	}
	sortOrder := "DESC"
	if query.SortOrder == "asc" {
		sortOrder = "ASC"
	}
	sqlQuery += fmt.Sprintf(" ORDER BY %s %s", sortBy, sortOrder)

	// Add pagination
	if query.Limit > 0 {
		sqlQuery += " LIMIT ?"
		args = append(args, query.Limit)
		if query.Offset > 0 {
			sqlQuery += " OFFSET ?"
			args = append(args, query.Offset)
		}
	}

	rows, err := ps.db.QueryContext(ctx, sqlQuery, args...)
	if err != nil {
		return nil, fmt.Errorf("failed to query patterns: %w", err)
	}
	defer rows.Close()

	return ps.scanPatterns(rows)
}

// GetPatternStats returns aggregated pattern statistics
func (ps *PatternStorage) GetPatternStats(ctx context.Context, timeRange *TimeRange) (*PatternStats, error) {
	ps.mutex.RLock()
	defer ps.mutex.RUnlock()

	stats := &PatternStats{
		PatternsByCategory: make(map[string]int),
		PatternsByLanguage: make(map[string]int),
		PatternsByImpact:   make(map[string]int),
	}

	// Base query for stats
	whereClause := ""
	args := make([]interface{}, 0)

	if timeRange != nil {
		whereClause = " WHERE created_at BETWEEN ? AND ?"
		args = append(args, timeRange.Start, timeRange.End)
	}

	// Total patterns
	query := "SELECT COUNT(*) FROM patterns" + whereClause
	if err := ps.db.QueryRowContext(ctx, query, args...).Scan(&stats.TotalPatterns); err != nil {
		return nil, fmt.Errorf("failed to get total patterns: %w", err)
	}

	// Patterns by category
	query = "SELECT category, COUNT(*) FROM patterns" + whereClause + " GROUP BY category"
	rows, err := ps.db.QueryContext(ctx, query, args...)
	if err != nil {
		return nil, fmt.Errorf("failed to get patterns by category: %w", err)
	}

	for rows.Next() {
		var category string
		var count int
		if err := rows.Scan(&category, &count); err == nil {
			stats.PatternsByCategory[category] = count
		}
	}
	rows.Close()

	// Patterns by language
	query = "SELECT language, COUNT(*) FROM patterns" + whereClause + " GROUP BY language"
	rows, err = ps.db.QueryContext(ctx, query, args...)
	if err != nil {
		return nil, fmt.Errorf("failed to get patterns by language: %w", err)
	}

	for rows.Next() {
		var language string
		var count int
		if err := rows.Scan(&language, &count); err == nil {
			stats.PatternsByLanguage[language] = count
		}
	}
	rows.Close()

	// Most frequent patterns
	query = "SELECT * FROM patterns" + whereClause + " ORDER BY occurrences DESC LIMIT 10"
	rows, err = ps.db.QueryContext(ctx, query, args...)
	if err != nil {
		return nil, fmt.Errorf("failed to get most frequent patterns: %w", err)
	}
	stats.MostFrequent, _ = ps.scanPatterns(rows)

	// Recently discovered patterns
	query = "SELECT * FROM patterns" + whereClause + " ORDER BY created_at DESC LIMIT 10"
	rows, err = ps.db.QueryContext(ctx, query, args...)
	if err != nil {
		return nil, fmt.Errorf("failed to get recent patterns: %w", err)
	}
	stats.RecentlyDiscovered, _ = ps.scanPatterns(rows)

	// Top rated patterns
	query = "SELECT * FROM patterns WHERE user_rating > 0" + strings.Replace(whereClause, "WHERE", "AND", 1) + " ORDER BY user_rating DESC LIMIT 10"
	rows, err = ps.db.QueryContext(ctx, query, args...)
	if err != nil {
		return nil, fmt.Errorf("failed to get top rated patterns: %w", err)
	}
	stats.TopRated, _ = ps.scanPatterns(rows)

	// Calculate average confidence
	query = "SELECT AVG(confidence) FROM patterns" + whereClause
	if err := ps.db.QueryRowContext(ctx, query, args...).Scan(&stats.AverageConfidence); err != nil {
		stats.AverageConfidence = 0.0
	}

	return stats, nil
}

// Helper methods

func (ps *PatternStorage) getPatternByID(ctx context.Context, patternID string) (*StoredPattern, error) {
	query := `SELECT id, name, description, category, language, pattern, examples, occurrences, 
			confidence, complexity, impact, recommendations, tags, metadata, first_seen, last_seen, 
			created_at, updated_at, project_paths, file_patterns, user_rating, auto_generated
			FROM patterns WHERE id = ?`

	row := ps.db.QueryRowContext(ctx, query, patternID)
	return ps.scanPattern(row)
}

func (ps *PatternStorage) scanPattern(row *sql.Row) (*StoredPattern, error) {
	var pattern StoredPattern
	var examplesJSON, recommendationsJSON, tagsJSON, metadataJSON, projectPathsJSON, filePatternsJSON string

	err := row.Scan(
		&pattern.ID,
		&pattern.Name,
		&pattern.Description,
		&pattern.Category,
		&pattern.Language,
		&pattern.Pattern,
		&examplesJSON,
		&pattern.Occurrences,
		&pattern.Confidence,
		&pattern.Complexity,
		&pattern.Impact,
		&recommendationsJSON,
		&tagsJSON,
		&metadataJSON,
		&pattern.FirstSeen,
		&pattern.LastSeen,
		&pattern.CreatedAt,
		&pattern.UpdatedAt,
		&projectPathsJSON,
		&filePatternsJSON,
		&pattern.UserRating,
		&pattern.AutoGenerated,
	)

	if err != nil {
		return nil, fmt.Errorf("failed to scan pattern: %w", err)
	}

	// Parse JSON fields
	json.Unmarshal([]byte(examplesJSON), &pattern.Examples)
	json.Unmarshal([]byte(recommendationsJSON), &pattern.Recommendations)
	json.Unmarshal([]byte(tagsJSON), &pattern.Tags)
	json.Unmarshal([]byte(metadataJSON), &pattern.Metadata)
	json.Unmarshal([]byte(projectPathsJSON), &pattern.ProjectPaths)
	json.Unmarshal([]byte(filePatternsJSON), &pattern.FilePatterns)

	return &pattern, nil
}

func (ps *PatternStorage) scanPatterns(rows *sql.Rows) ([]*StoredPattern, error) {
	var patterns []*StoredPattern

	for rows.Next() {
		var pattern StoredPattern
		var examplesJSON, recommendationsJSON, tagsJSON, metadataJSON, projectPathsJSON, filePatternsJSON string

		err := rows.Scan(
			&pattern.ID,
			&pattern.Name,
			&pattern.Description,
			&pattern.Category,
			&pattern.Language,
			&pattern.Pattern,
			&examplesJSON,
			&pattern.Occurrences,
			&pattern.Confidence,
			&pattern.Complexity,
			&pattern.Impact,
			&recommendationsJSON,
			&tagsJSON,
			&metadataJSON,
			&pattern.FirstSeen,
			&pattern.LastSeen,
			&pattern.CreatedAt,
			&pattern.UpdatedAt,
			&projectPathsJSON,
			&filePatternsJSON,
			&pattern.UserRating,
			&pattern.AutoGenerated,
		)

		if err != nil {
			return nil, fmt.Errorf("failed to scan pattern: %w", err)
		}

		// Parse JSON fields
		json.Unmarshal([]byte(examplesJSON), &pattern.Examples)
		json.Unmarshal([]byte(recommendationsJSON), &pattern.Recommendations)
		json.Unmarshal([]byte(tagsJSON), &pattern.Tags)
		json.Unmarshal([]byte(metadataJSON), &pattern.Metadata)
		json.Unmarshal([]byte(projectPathsJSON), &pattern.ProjectPaths)
		json.Unmarshal([]byte(filePatternsJSON), &pattern.FilePatterns)

		patterns = append(patterns, &pattern)
	}

	return patterns, rows.Err()
}

func (ps *PatternStorage) mergePatterns(existing, new *StoredPattern) *StoredPattern {
	// Merge logic - keep the best aspects of both patterns
	merged := *existing

	// Update confidence with weighted average
	merged.Confidence = (existing.Confidence*float64(existing.Occurrences) + new.Confidence) / float64(existing.Occurrences+1)

	// Merge examples, recommendations, and tags
	merged.Examples = ps.mergeStringSlices(existing.Examples, new.Examples)
	merged.Recommendations = ps.mergeStringSlices(existing.Recommendations, new.Recommendations)
	merged.Tags = ps.mergeStringSlices(existing.Tags, new.Tags)

	// Merge metadata
	for k, v := range new.Metadata {
		if merged.Metadata == nil {
			merged.Metadata = make(map[string]interface{})
		}
		merged.Metadata[k] = v
	}

	return &merged
}

func (ps *PatternStorage) mergeStringSlices(slice1, slice2 []string) []string {
	seen := make(map[string]bool)
	result := make([]string, 0)

	for _, item := range slice1 {
		if !seen[item] {
			result = append(result, item)
			seen[item] = true
		}
	}

	for _, item := range slice2 {
		if !seen[item] {
			result = append(result, item)
			seen[item] = true
		}
	}

	return result
}

func (ps *PatternStorage) containsString(slice []string, item string) bool {
	for _, s := range slice {
		if s == item {
			return true
		}
	}
	return false
}

func (ps *PatternStorage) loadIndex() {
	// Load all patterns into the indexer for fast searching
	ctx := context.Background()
	query := &PatternQuery{Limit: 10000} // Load up to 10k patterns

	patterns, err := ps.QueryPatterns(ctx, query)
	if err != nil {
		return
	}

	ps.indexer.mutex.Lock()
	defer ps.indexer.mutex.Unlock()

	for _, pattern := range patterns {
		ps.indexer.patterns[pattern.ID] = pattern
	}
}

// UpdateUserRating updates the user rating for a pattern
func (ps *PatternStorage) UpdateUserRating(ctx context.Context, patternID string, rating float64) error {
	ps.mutex.Lock()
	defer ps.mutex.Unlock()

	query := `UPDATE patterns SET user_rating = ?, updated_at = CURRENT_TIMESTAMP WHERE id = ?`
	_, err := ps.db.ExecContext(ctx, query, rating, patternID)
	return err
}

// DeletePattern removes a pattern from storage
func (ps *PatternStorage) DeletePattern(ctx context.Context, patternID string) error {
	ps.mutex.Lock()
	defer ps.mutex.Unlock()

	// Delete pattern (occurrences will be deleted by CASCADE)
	_, err := ps.db.ExecContext(ctx, "DELETE FROM patterns WHERE id = ?", patternID)
	if err != nil {
		return err
	}

	// Remove from cache and index
	ps.cache.Delete(context.Background(), patternID)

	ps.indexer.mutex.Lock()
	delete(ps.indexer.patterns, patternID)
	ps.indexer.mutex.Unlock()

	return nil
}
